<!DOCTYPE HTML>
<!--
	Phantom by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Kira Mathias-Prabhu | Portfolio: Generated Textures Part I</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/skippr.css" />
		<link href="https://fonts.googleapis.com/css2?family=Baloo+Bhaina+2&display=swap" rel="stylesheet">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">
		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Header -->
					<header id="header">
						<div class="inner">

							<!-- Logo -->
								<a href="index.html#portfolio" class="logo"><span class="title"> < Portfolio</span></a>

							<!-- Nav -->
								<nav>
									<ul>
										<li><a href="#menu">Menu</a></li>
									</ul>
								</nav>

						</div>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<h2>Menu</h2>
						<ul>
							<li><a href="index.html">Home</a></li>
							<li><a href="index.html#portfolio">Portfolio</a></li>
							<li><a href="generic.html">About Me</a></li>
							<li><a href="music.html">Music</a></li>
							<li><a href="docs/resume2020.pdf">Résumé</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
						<div class="inner">
							<h1>Generated Textures Part I</h1>
							<h4 class="project_type">Personal Project</h4>
								<div class="left-right-container">
								<div class="left_container">
								<h3>In Brief </h3>
								<p>I have always loved texture, and nature is the ultimate creator of textures. The goal of this project was to imagine new textures computationally with machine learning, using nature’s creations as inspiration. I develop a generative adversarial network (GAN) which I train on images of textures in nature. As it learns, it synthesizes new images of textures. These texture images combine the features of the input data in new ways based on what the network has 'learned' about textures in nature. The images generated by my neural network are two-dimensional 144x144 pixel RGB images. The results are interesting as-is, but I also see this as a proof of concept for using GANs, or encoder-decoder networks to generate or inform the design of new nano-structures, surfaces, materials, patterns, or prints. </p> 
								<p> The gallery to the right shows some of my results, generated throughout training, and from a few datasets described below.</p>
							</div>

								<div class="gallery_container right_container" style="width:400px;height:400px;">
									<div class="theTarget">
										<div style="background-image: url(images/gan_examples/epoch110_texture.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/epoch133_texture.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/epoch_237_texture.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/epoch52_nn_orig.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/epoch118_orig.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/example7.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/example8.png);background-size:contain;background-repeat:no-repeat;"></div>
									</div>
								</div>
							</div>
							<div class="container" style="width:100%;margin-top:1em;">
							<h3>Process </h3>
							<b>Network development</b>: I began with an implementation of Deep Convolutional GAN (DCGAN) in Keras based on the Tensorflow example <a href="https://www.tensorflow.org/tutorials/generative/dcgan" target="_blank">here</a>, and added layers to both the discriminator and generator to increase image dimension. I used soft, noisy labels, and different learning rates for the discriminator and generator, as suggested <a href="https://github.com/soumith/ganhacks" target="_blank">here</a>. I found that using a small batch size, dropout in both the discriminator and generator, leaky ReLU activations and batch normalization only in the generator improved my baseline network architecture.</p>
	
							</div>
							<div class="left-right-container" style="margin-top:1em; margin-bottom:1em; display:inline-block;">
							<div class="left_container" style="width:350px; height:350px;">
									<div id="theTarget" class="theTarget">
										<div style="background-image: url(images/gan_examples/aquatic1.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/aquatic2.png);background-size:contain;background-repeat:no-repeat;"></div>
										<div style="background-image: url(images/gan_examples/aquatic3.png);background-size:contain;background-repeat:no-repeat;"></div>
									</div>
								</div>
							<div class="right_container" style="padding-top:1em">
								<p>I evaluated the quality and progress of my network by the quality of the images output by the generator. Textures are an abstract subject to evaluate, so I compiled a training set of aquatic images to use while developing the network and tuning its hyperparameters. When it had produced the images to the left, I began using the texture training data to generate the final results you've seen.</p>
							</div>
						</div>
						<div>
							<p><b>Dataset Generation:</b>
							I created several datasets of approximately 1000 images by scraping images using the <a href="https://www.flickr.com/services/api/" target="_blank">Flickr API</a>. I began with a dataset of about 5000 images, but found that the images contained too much variation to for the network to learn anything interesting. I experimented with images of different sizes, and ultimately found that matching the input and output dimensions, as opposed to downsampling larger input images, produced the best results. I scraped images of size 150x150 pixels, which were then cropped to 144x144. I didn’t need to generate large images (DCGAN-based architectures typically are not able to synthesize large, high-resolution images), but did want them to be large enough to capture some interesting detail and variation.</p>
								<p>I also experimented with different sets of image queries. Initially, I manually inspected and filtered irrelevant images out of the datasets, but eventually found that the combination of queries that went into creating a training dataset influenced the output images more than the image quality. Once my network architecture was established, I created several datasets using different sets of Flickr queries. I built sets of queries based on qualities I hoped to see in the output textures, and image quality and availability on Flickr. Even so, as can be seen in the gallery below, I still ended up with many undesirable images. The network was surprisingly robust to undesirable data, but would likely produce better results with a carefully curated dataset.</br>
							<h4>Sample query sets</h4>
							<b>[animal_patterns, plant_patterns, bark, curves, lines, bio_patterns, nature_symmetry]</br>
							[bark, plant_curves, textures, macro_nature, nature symmetry, fractal, macro plant]</b><br/>
							<div class="theTarget" style="width:80%;height:550px;margin-left:10%;margin-top:2em;">
								<div style="background-image: url(images/training_good.png);background-size:contain;background-repeat:no-repeat;"></div>
								<div style="background-image: url(images/training_bad.png);background-size:contain;background-repeat:no-repeat;"></div>
							</div>
						</div>
						</div>

					</div>

				<!-- Footer -->

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="http://code.jquery.com/jquery-1.11.0.min.js"></script>
			<script src="assets/js/skippr.js"></script>
			<script>$(document).ready(function() {
									$(".theTarget").skippr();
			});</script>

	</body>
</html>